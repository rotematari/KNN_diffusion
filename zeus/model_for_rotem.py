# -*- coding: utf-8 -*-
"""model for rotem

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A_xSOXYqc_eAIoXg-51wt-qQykR82NAu

    !pip install transformers
    !pip install diffusers
    !pip install ipyplot
    !pip install accelerate
"""



import os 
import torch
import torch.nn as nn
import numpy as np
import random as rn
import pickle
import torchvision
from accelerate import Accelerator
from torch.amp.autocast_mode import autocast
from diffusers import UNet2DModel,DDPMScheduler,DDPMPipeline
from transformers import get_cosine_schedule_with_warmup
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

from dataclasses import dataclass
import torch.nn.functional as F
import math
from tqdm.auto import tqdm
import datetime
from os.path import join
from PIL import Image



@dataclass
class TrainingConfig:
    image_size = 32  # the generated image resolution
    train_batch_size = 64
    eval_batch_size = 16  # how many images to sample during evaluation
    num_epochs = 1000
    gradient_accumulation_steps = 1
    learning_rate = 1e-4
    lr_warmup_steps = 500
    save_image_epochs = 50
    save_model_epochs = 100
    mixed_precision = 'fp16'  # `no` for float32, `fp16` for automatic mixed precision
    output_dir = r'./results'
    seed = 0



def make_grid(images, rows, cols):
    w, h = images[0].size
    grid = Image.new('RGB', size=(cols*w, rows*h))
    for i, image in enumerate(images):
        grid.paste(image, box=(i%cols*w, i//cols*h))
    return grid

def evaluate(config, epoch, pipeline):
    # Sample some images from random noise (this is the backward diffusion process).
    # The default pipeline output type is `List[PIL.Image]`
    images = pipeline(
        batch_size = config.eval_batch_size,
        generator=torch.manual_seed(config.seed),
    ).images

    # Make a grid out of the images
    image_grid = make_grid(images, rows=4, cols=4)

    # Save the images
    test_dir = os.path.join(config.output_dir, "samples")
    os.makedirs(test_dir, exist_ok=True)
    image_grid.save(f"{test_dir}/{epoch:04d}.png")

def train_loop(config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler,device='cpu'):
    
    now = datetime.datetime.now()
    timestamp = now.strftime('%m_%d_%H_%M')
    
    # Initialize accelerator and tensorboard logging
    accelerator = Accelerator(
        mixed_precision=config.mixed_precision,
        gradient_accumulation_steps=config.gradient_accumulation_steps

    )

    # Prepare everything
    # There is no specific order to remember, you just need to unpack the
    # objects in the same order you gave them to the prepare method.
    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
        model, optimizer, train_dataloader, lr_scheduler
    )

    global_step = 0

    # Now you train the model
    for epoch in range(config.num_epochs):
        progress_bar = tqdm(total=len(train_dataloader), disable=not accelerator.is_local_main_process)
        progress_bar.set_description(f"Epoch {epoch}")
        epoch_losses=[]

        for step, (batch,lables) in enumerate(train_dataloader):
            clean_images = batch
            # Sample noise to add to the images
            noise = torch.randn(clean_images.shape).to(clean_images.device)
            bs = clean_images.shape[0]

            # Sample a random timestep for each image
            timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (bs,), device=clean_images.device).long()

            #class label tensor
            lables=lables.to(device)

            # Add noise to the clean images according to the noise magnitude at each timestep
            # (this is the forward diffusion process)
            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)

            with accelerator.accumulate(model):
                # Predict the noise residual
                noise_pred = model(noisy_images, timesteps, lables ,return_dict=False)[0]
                loss = F.mse_loss(noise_pred, noise)
                epoch_losses.append(loss.item())
                accelerator.backward(loss)

                accelerator.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                lr_scheduler.step()
                optimizer.zero_grad()

            progress_bar.update(1)
            logs = {"loss": loss.detach().item(), "lr": lr_scheduler.get_last_lr()[0], "step": global_step}
            progress_bar.set_postfix(**logs)
            #accelerator.log(logs, step=global_step)
            global_step += 1
        print(f"avg epoch loss was {sum(epoch_losses)/len(epoch_losses)}")
        if (epoch) % config.save_model_epochs == 0 or epoch == config.num_epochs - 1:
            pipeline = DDPMPipeline(unet=accelerator.unwrap_model(model), scheduler=noise_scheduler)

            pipeline.save_pretrained(config.output_dir)

            evaluate(config, epoch, pipeline)

            path = r'./results/saved_models'
            file_name = f'checkpoint_epoch_{epoch}_time_{timestamp}'
            accelerator.save_model(model,join(path,file_name))
            print("saved")




def main():


    # Get the absolute path of the file
    file_path = os.path.abspath(__file__)

    # Get the directory containing the file
    file_dir = os.path.dirname(file_path)

    # Change the current working directory to the file's directory
    os.chdir(file_dir)

    rn.seed(0)
    torch.manual_seed(0)
    cuda_check = input("if cuda number has been check press 1 :\n")


    if cuda_check != '1':
        print("check cuda !!")

        return 


    device = 'cuda:' if torch.cuda.is_available() else 'cpu'

    TRANSFORM = transforms.Compose(
        (transforms.ToTensor(), transforms.RandomHorizontalFlip(),transforms.Normalize([0.5], [0.5])))


    dataset = torchvision.datasets.CIFAR10(root=r'./data', train=True,
                                            download=True, transform=TRANSFORM)
    config = TrainingConfig()

    train_dataloader = DataLoader(dataset, batch_size=config.train_batch_size, shuffle=True)

    model = UNet2DModel(
        sample_size=config.image_size,  # the target image resolution
        in_channels=3,  # the number of input channels, 3 for RGB images
        out_channels=3,  # the number of output channels
        layers_per_block=2,  # how many ResNet layers to use per UNet block
        block_out_channels=(128, 256, 512),  # the number of output channes for each UNet block
        class_embed_type=None,
        num_class_embeds=10,
        down_block_types=(
            "DownBlock2D",  # a regular ResNet downsampling block
            "AttnDownBlock2D",  # a ResNet downsampling block with spatial self-attention
            "AttnDownBlock2D",
        ),
        up_block_types=(
            "AttnUpBlock2D",  # a regular ResNet upsampling block
            "AttnUpBlock2D",  # a ResNet upsampling block with spatial self-attention
            "UpBlock2D"
        ),
    )

    noise_scheduler = DDPMScheduler(num_train_timesteps=1000)

    optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)

    lr_scheduler = get_cosine_schedule_with_warmup(
        optimizer=optimizer,
        num_warmup_steps=config.lr_warmup_steps,
        num_training_steps=(len(train_dataloader) * config.num_epochs),
    )



    train_loop(config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler,device=device)

if __name__ == "__main__":

    main()
    
    
    
    